
# ===========================================
timm              0.3.2
torch             1.10.0+cu111
torchvision       0.11.1+cu111
# ===========================================


Traceback (most recent call last):
  File "/gpfsdata/home/wenshuai/projects/ActiveFT_xu/deit/main.py", line 13, in <module>
    from timm.data import Mixup
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/__init__.py", line 2, in <module>
    from .models import create_model, list_models, is_model, list_modules, model_entrypoint, \
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/__init__.py", line 1, in <module>
    from .cspnet import *
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/cspnet.py", line 20, in <module>
Traceback (most recent call last):
  File "/gpfsdata/home/wenshuai/projects/ActiveFT_xu/deit/main.py", line 13, in <module>
    from timm.data import Mixup
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/__init__.py", line 2, in <module>
    from .models import create_model, list_models, is_model, list_modules, model_entrypoint, \
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/__init__.py", line 1, in <module>
    from .cspnet import *
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/cspnet.py", line 20, in <module>
    from .helpers import build_model_with_cfg
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/helpers.py", line 17, in <module>
    from .helpers import build_model_with_cfg
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/helpers.py", line 17, in <module>
    from .layers import Conv2dSame, Linear
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/layers/__init__.py", line 7, in <module>
    from .layers import Conv2dSame, Linear
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/layers/__init__.py", line 7, in <module>
    from .cond_conv2d import CondConv2d, get_condconv_initializer    
from .cond_conv2d import CondConv2d, get_condconv_initializer
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/layers/cond_conv2d.py", line 16, in <module>
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/layers/cond_conv2d.py", line 16, in <module>
    from .helpers import to_2tuple
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/layers/helpers.py", line 6, in <module>
    from .helpers import to_2tuple
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/layers/helpers.py", line 6, in <module>
        from torch._six import container_abcsfrom torch._six import container_abcs

ImportErrorImportError: : cannot import name 'container_abcs' from 'torch._six' (/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/_six.py)cannot import name 'container_abcs' from 'torch._six' (/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/_six.py)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 23948) of binary: /gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/bin/python
Traceback (most recent call last):
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/distributed/run.py", line 710, in run
    elastic_launch(
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-07-18_16:56:15
  host      : node19
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 23949)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-07-18_16:56:15
  host      : node19
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 23948)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

[Solution]
vim /gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/timm/models/layers/helpers.py

# *************************************************** modfied by @xws **********************************
#from torch._six import container_abcs
import torch
TORCH_MAJOR = int(torch.__version__.split('.')[0])
TORCH_MINOR = int(torch.__version__.split('.')[1])
if TORCH_MAJOR == 1 and TORCH_MINOR < 8:
    from torch._six import container_abcs
else:
    import collections.abc as container_abcs

# *************************************************** modfied by @xws **********************************

/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torchvision/transforms/functional.py:404: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(

[Solution][Trying]
vim datasets.py:131, transforms.Resize(size, interpolation=3)

# TODO: Once torchscript supports Enums with staticmethod
# this can be put into InterpolationMode as staticmethod
def _interpolation_modes_from_int(i: int) -> InterpolationMode:
    inverse_modes_mapping = {
        0: InterpolationMode.NEAREST,
        2: InterpolationMode.BILINEAR,
        3: InterpolationMode.BICUBIC,
        4: InterpolationMode.BOX,
        5: InterpolationMode.HAMMING,
        1: InterpolationMode.LANCZOS,
    }
    return inverse_modes_mapping[i]

from torchvision import transforms

################################ modified by @xws ##############################
# change line 131: transforms.Resize(size, interpolation=3) to below two lines

inter3 = transforms.transforms._interpolation_modes_from_int(3)
transforms.Resize(size, interpolation=inter3)

# However, warning still exists, even double call than before.
################################ modified by @xws ##############################

[Solution][not good]
# -----------------------------------------------------------
1. python -W ignore file.py                           # [NO]
2. import warnings;warnings.filterwarnings("ignore")  # [OK]
3. import warnings
   with warnings.catch_warnings():
       warnings.simplefilter("ignore")
       a = 1/0.0  # cancel warning for part code
# -----------------------------------------------------------

/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please change it to read from `os.environ['LOCAL_RANK']` instead. 
See https://pytorch.org/docs/stable/distributed.html#launch-utility for further instructions
  warnings.warn(
WARNING:torch.distributed.run:

/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

/gpfsdata/home/wenshuai/miniconda3/envs/ActiveFT/lib/python3.9/site-packages/torchvision/transforms/functional.py:404: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(


